{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data-x](https://raw.githubusercontent.com/afo/data-x-plaksha/master/imgsource/dx_logo.png)\n",
    "\n",
    "\n",
    "# Intro to Deep Learning with Keras\n",
    "\n",
    "#### Author: Alexander Fred Ojala\n",
    "\n",
    "_____\n",
    "\n",
    "# Why Keras\n",
    "Modular, powerful and intuitive Deep Learning python library integrated with TensorFlow.\n",
    "* Minimalist, user-friendly interface\n",
    "* Works on CPUs and GPUs\n",
    "* Open-source, developed and maintained by a community of contributors, and\n",
    "publicly hosted on github\n",
    "* Extremely well documented, lots of working examples: https://keras.io/\n",
    "* Very shallow learning curve â€”> it is by far one of the best tools for experimenting, both for beginners and experts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison: Deep Learning Framewroks\n",
    "Compile code down to the deep learning framework (i.e. takes longer to run). See comparison of speed for different DL frameworks:\n",
    "\n",
    "<img src='imgs/train_times.png' width=600px></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras #canonical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras \"Hello World\" on Iris\n",
    "\n",
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== =====\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_iris()\n",
    "\n",
    "print(data.DESCR[:980])\n",
    "\n",
    "x = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode y\n",
    "import pandas as pd\n",
    "\n",
    "y = pd.get_dummies(y).values\n",
    "y[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(90, 3)\n",
      "(60, 4)\n"
     ]
    }
   ],
   "source": [
    "# train test split, plus randomize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, test_size=0.4,\n",
    "                                                    random_state=1337,\n",
    "                                                   shuffle=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sequential model\n",
    "The simplest model in Keras is the Sequential model, a linear stack of layers.\n",
    "\n",
    "* **Sequential model** linear stack of layers: It allows us to build NNs like legos, by adding one layer on top of the other, and swapping layers\n",
    "\n",
    "* Graph: multi-input, multi-output, with arbitrary connections inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data structure in Keras is a model\n",
    "# The model is an object in which we organize layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model initialization\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential() # instantiate empty Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import layer classes and stack layers (in an NN model for example), by using `.add()`\n",
    "\n",
    "# Specifying the input shape\n",
    "\n",
    "The model needs to know what input shape it should expect. For this reason, the first layer in a  Sequential model needs to receive information about its input shape. There are several possible ways to do this:\n",
    "\n",
    "* Pass an input_shape argument to the first layer. This is a shape tuple (a tuple of integers or `None` entries, where `None` indicates that any positive integer may be expected).\n",
    "* Some 2D layers, such as Dense, support the specification of their input shape via the argument  input_dim, and some 3D temporal layers support the arguments `input_dim` and `input_length`.\n",
    "\n",
    "\n",
    "**The following snippets are strictly equivalent:**\n",
    "> * `model.add(Dense(32, input_shape=(784,)))`\n",
    "> * `model.add(Dense(32, input_dim=784))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model contruction (architecture build computational graph)\n",
    "from keras.layers import Dense\n",
    "\n",
    "model.add( Dense(units=64, activation='relu', input_shape=(4,) ))\n",
    "model.add( Dense(units=3, activation='softmax') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation phase, specify learning process\n",
    "\n",
    "Run `.compile()` on the model to specify learning process.\n",
    "\n",
    "Before training a model, you need to configure the learning process, which is done via the  compile method. It receives three arguments:\n",
    "\n",
    "* **A loss function:** This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (such as `categorical_crossentropy` or `mse`), or it can be an objective function.\n",
    "* **An optimizer:** This could be the string identifier of an existing optimizer (such as `rmsprop`, `gradientdescent`, or `adagrad`), or an instance of the Optimizer class.\n",
    "* **(Optional) A list of metrics:** For any classification problem you will want to set this to `metrics=['accuracy']`. A metric could be the string identifier of an existing metric or a custom metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also specify our own optimizer, loss function or metric (or code it ourselves)\n",
    "\n",
    "```python\n",
    "# or with we can specify loss function\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = SGD(lr=0.001, momentum = 0.9, nesterov=True),\n",
    "             metrics = ['accuracy'])\n",
    "```\n",
    "\n",
    "### Different optimizers and their trade-offs\n",
    "To read more about gradient descent optimizers, hyperparameters etc. This is a recommended reading: http://ruder.io/optimizing-gradient-descent/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 10:39:18.163702: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 1.1900 - accuracy: 0.2111\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 714us/step - loss: 1.1166 - accuracy: 0.2333\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 790us/step - loss: 1.0704 - accuracy: 0.3444\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 615us/step - loss: 1.0359 - accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 890us/step - loss: 1.0100 - accuracy: 0.2889\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 803us/step - loss: 0.9883 - accuracy: 0.3000\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 733us/step - loss: 0.9705 - accuracy: 0.3556\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 880us/step - loss: 0.9552 - accuracy: 0.3444\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 653us/step - loss: 0.9380 - accuracy: 0.4111\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 911us/step - loss: 0.9229 - accuracy: 0.4222\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 911us/step - loss: 0.9070 - accuracy: 0.4556\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.8910 - accuracy: 0.5778\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.8751 - accuracy: 0.6000\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.8610 - accuracy: 0.6444\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 934us/step - loss: 0.8457 - accuracy: 0.6556\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 859us/step - loss: 0.8329 - accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 823us/step - loss: 0.8190 - accuracy: 0.6889\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.8065 - accuracy: 0.6889\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.7935 - accuracy: 0.7444\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 898us/step - loss: 0.7809 - accuracy: 0.7778\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 929us/step - loss: 0.7688 - accuracy: 0.7556\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 948us/step - loss: 0.7565 - accuracy: 0.7556\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.7446 - accuracy: 0.7556\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 920us/step - loss: 0.7336 - accuracy: 0.7778\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 806us/step - loss: 0.7224 - accuracy: 0.7778\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 944us/step - loss: 0.7123 - accuracy: 0.8222\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 834us/step - loss: 0.7016 - accuracy: 0.8667\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 977us/step - loss: 0.6913 - accuracy: 0.8556\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 898us/step - loss: 0.6814 - accuracy: 0.8444\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 937us/step - loss: 0.6719 - accuracy: 0.8333\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 821us/step - loss: 0.6626 - accuracy: 0.8222\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 890us/step - loss: 0.6533 - accuracy: 0.8333\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 778us/step - loss: 0.6450 - accuracy: 0.8667\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.8667\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.8889\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 913us/step - loss: 0.6203 - accuracy: 0.8778\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 926us/step - loss: 0.6117 - accuracy: 0.9000\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 910us/step - loss: 0.6041 - accuracy: 0.9111\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 827us/step - loss: 0.5966 - accuracy: 0.9000\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5892 - accuracy: 0.9000\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 880us/step - loss: 0.5822 - accuracy: 0.9000\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 911us/step - loss: 0.5752 - accuracy: 0.9111\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 972us/step - loss: 0.5686 - accuracy: 0.9000\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 867us/step - loss: 0.5622 - accuracy: 0.9222\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 904us/step - loss: 0.5554 - accuracy: 0.9333\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 740us/step - loss: 0.5504 - accuracy: 0.8889\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 753us/step - loss: 0.5433 - accuracy: 0.8889\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 762us/step - loss: 0.5371 - accuracy: 0.8889\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 767us/step - loss: 0.5313 - accuracy: 0.8889\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 728us/step - loss: 0.5254 - accuracy: 0.9222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x293a01ac0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model by iterating over the training data in batches\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 50, batch_size= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.949999988079071"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Evaluate the model Accuracy on test set\n",
    "model.evaluate(X_test, y_test, batch_size=60,verbose=False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predictions on new data:\n",
    "\n",
    "class_probabilities = model.predict(X_test, batch_size=128)\n",
    "\n",
    "# gives output of the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09266351, 0.48843595, 0.41890052],\n",
       "       [0.8097885 , 0.13662812, 0.05358344],\n",
       "       [0.02906828, 0.44778043, 0.52315134],\n",
       "       [0.749028  , 0.17954369, 0.07142833],\n",
       "       [0.02168042, 0.43500322, 0.5433163 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probabilities[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "---------\n",
    "# End here\n",
    "---------\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras DNN on MNIST\n",
    "\n",
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "img_dim = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_dim)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_dim)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model to stack layers\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model contruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model constructor\n",
    "model = Sequential()\n",
    "# Add layers sequentially\n",
    "model.add(Dense(300, activation=tf.nn.leaky_relu, input_shape=(784,) ) )\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "# Second..\n",
    "model.add(Dense(200, activation=tf.nn.leaky_relu))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "# Third..\n",
    "model.add(Dense(100, activation=tf.nn.leaky_relu))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='adam', #chooses suitable learning rate for you.\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=128,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(3),history.history['accuracy'])\n",
    "plt.title('accuracy per iteration')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great accuracy for an ANN in so few training steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN in Keras\n",
    "## 99.5% accuracy on MNIST in 12 epochs\n",
    "\n",
    "Note this takes ~1hr to run on a CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# notice that we don't flatten image\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "#normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almost LeNet architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(12),history.history['accuracy'])\n",
    "plt.title('accuracy per iteration')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
