{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome\n",
    "-------\n",
    "\n",
    "Source: https://github.com/piotrszul/spark-tutorial (great tutorials to get up to speed)\n",
    "\n",
    "Welcome to the Apache Spark tutorial notebooks.\n",
    "\n",
    "This very simple notebook is designed to test that your environment is setup correctly.\n",
    "\n",
    "Please `Run All` cells. \n",
    "\n",
    "The notebook should run without errors and you should see a histogram plot at the end.\n",
    "\n",
    "(You can also check the expected output [here](https://piotrszul.github.io/spark-tutorial/notebooks/0.1_Welcome.html))\n",
    "\n",
    "\n",
    "#### Let's go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that there are some input data available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿The Project Gutenberg EBook of The Prince, by Nicolo Machiavelli\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org\n",
      "\n",
      "\n",
      "Title: The Prince\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# All the test data sets are located in the `data` directory.\n",
    "# You can preview them using unix command such as `cat`, `head`, `tail`,  `ls`,  etc. \n",
    "# in `shell` cells marked with the `%%sh` magic, e.g.: \n",
    "\n",
    "head -n 10 prince_by_machiavelli.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if spark is available and what version are we using (should be 2.1+):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `spark` is the main entry point for all spark related operations.\n",
    "# It is an instance of SparkSession and pyspark automatically creates one for you.\n",
    "# Another one is `sc` an instance of SparkContext, which is used for low lever RRD API.\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to run a simple `Spark` program to compute the number of occurences of words in Machiavelli's \"Prince\", and display ten most frequent ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3108, 'the'), (2107, 'to'), (1935, 'and'), (1802, 'of'), (993, 'in'), (920, 'he'), (779, 'a'), (745, 'that'), (640, 'his'), (585, 'it')]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import re\n",
    "\n",
    "\n",
    "# Here we use Spark RDD API to split a text file into invividual words, \n",
    "# to count the number of occurences of each word and to take top 10 most frequent words.\n",
    "\n",
    "wordCountRDD = sc.textFile('prince_by_machiavelli.txt') \\\n",
    "        .flatMap(lambda line: re.split(r'[^a-z\\-\\']+', line.lower())) \\\n",
    "        .filter(lambda word: len(word) > 0 ) \\\n",
    "        .map(lambda word: (word, 1)) \\\n",
    "        .reduceByKey(operator.add)\n",
    "\n",
    "# `take()` function takes the first n elements of an RDD \n",
    "# and returns them in a python `list` object, \n",
    "        \n",
    "top10Words = wordCountRDD \\\n",
    "    .map(lambda x: (x[1],x[0])) \\\n",
    "    .sortByKey(False) \\\n",
    "    .take(10)\n",
    "    \n",
    "    \n",
    "# which can then be printed out\n",
    "print(top10Words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark SQL is a higer level API for structured data. The data are represented in `data frames` - table like object with columns and rows concenptully similar to `panadas` or `R` data fames.\n",
    "\n",
    "Let's use Spark SQL to display a table with the 10 least frequent words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       word|count|\n",
      "+-----------+-----+\n",
      "|      nelli|    1|\n",
      "|  impressed|    1|\n",
      "|constitutes|    1|\n",
      "|bartolommea|    1|\n",
      "|   guidance|    1|\n",
      "|   currents|    1|\n",
      "|    prophet|    1|\n",
      "|  furnished|    1|\n",
      "|   missions|    1|\n",
      "|       gibe|    1|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A data frame can be created from an RDD;\n",
    "# schema defines the names (and types) of columns.\n",
    "\n",
    "wordCountDF = spark.createDataFrame(wordCountRDD, schema = ['word', 'count'])\n",
    "\n",
    "# it just means: sort by column `count` and take the first ten elements\n",
    "\n",
    "bottom10Words = wordCountDF.sort('count').limit(10)\n",
    "\n",
    "# `display` function can be used to display data frames (and also all other sorts of objects)\n",
    "bottom10Words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the results to a csv file.\n",
    "\n",
    "For the tutorial all the output files are saved in the `output` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data frames can be saved in many common 'table' formats, for example `csv`.\n",
    "# the `mode='overwrite'` tells Spark to overwite the output file is it exists\n",
    "\n",
    "wordCountDF.write.csv('output/prince-word-count.csv', mode='overwrite', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preview the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 60\n",
      "-rw-r--r-- 1 afo afo 28291 Apr 25 12:23 part-00000-f7acadc0-2990-42db-b4f5-427fd1dcf361-c000.csv\n",
      "-rw-r--r-- 1 afo afo 28733 Apr 25 12:23 part-00001-f7acadc0-2990-42db-b4f5-427fd1dcf361-c000.csv\n",
      "-rw-r--r-- 1 afo afo     0 Apr 25 12:23 _SUCCESS\n",
      "\n",
      "Content:\n",
      "word,count\n",
      "project,87\n",
      "gutenberg,36\n",
      "ebook,11\n",
      "of,1802\n",
      "prince,221\n",
      "machiavelli,54\n",
      "this,366\n",
      "is,437\n",
      "use,30\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "\n",
    "# Same as with the input data sets, we can use the `%%sh` cells to preview the \n",
    "# files produced to the `output` directory.\n",
    "\n",
    "# Please note that output we have produced above is actually a directory:\n",
    "\n",
    "ls  -l output/prince-word-count.csv\n",
    "\n",
    "# The `part-*` files inside contain the actual data.\n",
    "\n",
    "echo\n",
    "echo \"Content:\"\n",
    "\n",
    "head -n 10 output/prince-word-count.csv/part-00000-*.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can use python `matplotlib` to visualise the result.\n",
    "\n",
    "Let's plot the histogram of the distribution of word counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADbJJREFUeJzt3W2spHdZx/Hvz+0DBkhpKZqmD3brNg37wkBzUogaYhTLFrIUCdHdmIjYsAGt0Re+WIIx+A5M9EVDtVlCUzCkpdYHlrCkEqRpTGrpFkvZuik91JIe27CLlfXhhbV4+WLupSfHPWfnnDmzM3Px/SQnZ+Y/c8+5/nvP+e2c675n/qkqJEl9/cisC5AkTZdBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1Nx5sy4A4NJLL62rr7561mVI0kJ59NFHv1tVrzvb/WYa9En2Ant37drF0aNHZ1mKJC2cJN8e534zbd1U1eer6sBFF100yzIkqTV79JLU3EyDPsneJIdOnTo1yzIkqTVbN5LUnK0bSWrOoJek5uzRS1Jz9uglqbm5eGfsJK4++IUtb/vMR9+xjZVI0nyyRy9Jzdmjl6Tm7NFLUnO2biSpOYNekpoz6CWpOQ/GSlJzHoyVpOZs3UhScwa9JDVn0EtScwa9JDVn0EtSc55eKUnNeXqlJDVn60aSmjPoJak5g16SmjPoJak5g16SmjPoJak5g16SmvMNU5LUnG+YkqTmbN1IUnMGvSQ1Z9BLUnMGvSQ1Z9BLUnMGvSQ1Z9BLUnMGvSQ1Z9BLUnMGvSQ1t+1Bn+T1Se5Icl+SD27340uSNmesoE9yZ5ITSY6tGd+T5Mkky0kOAlTV8ar6APDLwNL2lyxJ2oxxX9HfBexZPZBkB3A7cBOwG9ifZPdw2zuBvwe+vG2VSpK2ZKygr6oHgRfWDN8ALFfV01X1InAPcPNw/8NV9dPAr25nsZKkzTtvgm0vB55ddX0FeFOSnwPeDVwIHFlv4yQHgAMAV1111QRlSJI2MknQ5wxjVVUPAA+cbeOqOgQcAlhaWqoJ6pAkbWCSs25WgCtXXb8CeG6yciRJ222SoH8EuDbJziQXAPuAw5t5AJcSlKTpG/f0yruBh4DrkqwkuaWqXgJuBe4HjgP3VtUTm/nhLiUoSdM3Vo++qvavM36EDQ64nk2SvcDeXbt2bfUhJEln4eLgktScn3UjSc3NNOg9GCtJ02frRpKas3UjSc0Z9JLUnD16SWrOHr0kNWfrRpKaM+glqTl79JLUnD16SWrO1o0kNWfQS1JzBr0kNefBWElqzoOxktScrRtJas6gl6TmDHpJas6gl6TmDHpJas7TKyWpOU+vlKTmbN1IUnMGvSQ1Z9BLUnMGvSQ1Z9BLUnMGvSQ1Z9BLUnO+YUqSmvMNU5LUnK0bSWrOoJek5gx6SWrOoJek5gx6SWrOoJek5gx6SWrOoJek5gx6SWrOoJek5qYS9EneleQTST6X5MZp/AxJ0njGDvokdyY5keTYmvE9SZ5MspzkIEBV/U1VvR/4deBXtrViSdKmbOYV/V3AntUDSXYAtwM3AbuB/Ul2r7rL7w+3S5JmZOygr6oHgRfWDN8ALFfV01X1InAPcHNGPgZ8saq+tn3lSpI2a9Ie/eXAs6uurwxjvw28FXhPkg+cacMkB5IcTXL05MmTE5YhSVrPeRNunzOMVVXdBty20YZVdQg4BLC0tFQT1iFJWsekr+hXgCtXXb8CeG7Cx5QkbaNJg/4R4NokO5NcAOwDDo+7sUsJStL0beb0yruBh4DrkqwkuaWqXgJuBe4HjgP3VtUT4z6mSwlK0vSN3aOvqv3rjB8BjmzlhyfZC+zdtWvXVjaXJI3BxcElqTk/60aSmptp0HswVpKmz9aNJDVn60aSmjPoJak5e/SS1Jw9eklqztaNJDVn0EtSc/boJak5e/SS1JytG0lqzqCXpOYMeklqzoOxktScB2MlqTlbN5LUnEEvSc0Z9JLUnEEvSc0Z9JLUnKdXSlJznl4pSc3ZupGk5gx6SWrOoJek5s6bdQGzdPXBL0y0/TMffcc2VSJJ0+MreklqzqCXpOYMeklqzjdMSVJzvmFKkpqzdSNJzRn0ktScQS9JzRn0ktScQS9JzRn0ktScQS9JzRn0ktScQS9JzRn0ktTctgd9kmuSfDLJfdv92JKkzRsr6JPcmeREkmNrxvckeTLJcpKDAFX1dFXdMo1iJUmbN+4KU3cBHwc+fXogyQ7gduAXgRXgkSSHq+qftrvIeTXJClWuTiXpXBnrFX1VPQi8sGb4BmB5eAX/InAPcPM21ydJmtAkPfrLgWdXXV8BLk/y2iR3AG9M8qH1Nk5yIMnRJEdPnjw5QRmSpI1Msjh4zjBWVfWvwAfOtnFVHQIOASwtLdUEdUiSNjDJK/oV4MpV168AntvMA7jClCRN3yRB/whwbZKdSS4A9gGHN/MArjAlSdM37umVdwMPAdclWUlyS1W9BNwK3A8cB+6tqiemV6okaSvG6tFX1f51xo8AR7b6w5PsBfbu2rVrqw8hSToLFweXpOb8rBtJam6mQe9ZN5I0fbZuJKk5WzeS1JxBL0nN2aOXpObs0UtSc7ZuJKk5g16SmpvkY4on9sP8EQiuTiXpXLFHL0nN2bqRpOYMeklqzqCXpOZ8w5QkNefBWElqztaNJDVn0EtScwa9JDVn0EtScwa9JDXn6ZWS1JynV0pSc7ZuJKk5g16SmjPoJak5g16SmjPoJak5g16SmjPoJak5FwdfQJMsLD4pFyaXFo9vmJKk5mzdSFJzBr0kNWfQS1JzBr0kNWfQS1JzBr0kNWfQS1JzBr0kNWfQS1JzBr0kNbftn3WT5JXAnwIvAg9U1We2+2dIksY31iv6JHcmOZHk2JrxPUmeTLKc5OAw/G7gvqp6P/DOba5XkrRJ47Zu7gL2rB5IsgO4HbgJ2A3sT7IbuAJ4drjb97enTEnSVo0V9FX1IPDCmuEbgOWqerqqXgTuAW4GVhiF/diPL0mankl69Jfz8it3GAX8m4DbgI8neQfw+fU2TnIAOABw1VVXTVCGzqVJPgv/h/Gz7Ge5dsBW/TDup0lMuo/Pxb/3JEGfM4xVVf0X8L6zbVxVh4BDAEtLSzVBHZKkDUzSWlkBrlx1/Qrguc08QJK9SQ6dOnVqgjIkSRuZJOgfAa5NsjPJBcA+4PBmHsAVpiRp+sY9vfJu4CHguiQrSW6pqpeAW4H7gePAvVX1xPRKlSRtxVg9+qrav874EeDIVn+4i4NL0vS5OLgkNed57pLU3EyD3rNuJGn6bN1IUnOpmv17lZKcBL69xc0vBb67jeXMgnOYD85hPjiH8f1EVb3ubHeai6CfRJKjVbU06zom4Rzmg3OYD85h+3kwVpKaM+glqbkOQX9o1gVsA+cwH5zDfHAO22zhe/SSpI11eEUvSdrAQgf9OmvWzqUkzyT5RpLHkhwdxi5J8qUkTw3fLx7Gk+S2YV6PJ7l+RjX/v7WCt1JzkvcO938qyXvnYA4fSfIvw754LMnbV932oWEOTyZ526rxmTzXklyZ5CtJjid5IsnvDOMLsx82mMMi7YdXJPlqkq8Pc/jDYXxnkoeHf9PPDp/kS5ILh+vLw+1Xn21uU1VVC/kF7AC+BVwDXAB8Hdg967o2qPcZ4NI1Y38EHBwuHwQ+Nlx+O/BFRou7vBl4eEY1vwW4Hji21ZqBS4Cnh+8XD5cvnvEcPgL83hnuu3t4Hl0I7ByeXztm+VwDLgOuHy6/GvjmUOfC7IcN5rBI+yHAq4bL5wMPD/++9wL7hvE7gA8Ol38TuGO4vA/47EZzm3b9i/yKfr01axfJzcCnhsufAt61avzTNfIPwGuSXHaui6szrxW82ZrfBnypql6oqn8DvsSaheanaZ05rOdm4J6q+u+q+mdgmdHzbGbPtap6vqq+Nlz+D0YfCX45C7QfNpjDeuZxP1RV/edw9fzhq4CfB+4bxtfuh9P75z7gF5KE9ec2VYsc9Gdas3ajJ8+sFfC3SR7NaL1cgB+vqudh9MsA/NgwPs9z22zN8zqXW4fWxp2n2x7M+RyGP//fyOjV5ELuhzVzgAXaD0l2JHkMOMHoP8pvAd+r0doca+v5Qa3D7aeA1zKjOSxy0J9xzdpzXsX4fqaqrgduAn4ryVs2uO+izQ3Wr3ke5/JnwE8CbwCeB/54GJ/bOSR5FfCXwO9W1b9vdNczjM3rHBZqP1TV96vqDYyWTb0BeP0G9czVHBY56Cdes/Zcqqrnhu8ngL9m9ET5zumWzPD9xHD3eZ7bZmueu7lU1XeGX9r/BT7By386z+UckpzPKCA/U1V/NQwv1H440xwWbT+cVlXfAx5g1KN/TZLTCzitrucHtQ63X8SohTiTOSxy0E+8Zu25kuSVSV59+jJwI3CMUb2nz354L/C54fJh4NeGMyjeDJw6/Wf6HNhszfcDNya5ePjT/MZhbGbWHO/4JUb7AkZz2DecMbETuBb4KjN8rg193U8Cx6vqT1bdtDD7Yb05LNh+eF2S1wyXfxR4K6NjDV8B3jPcbe1+OL1/3gP8XY2Oxq43t+ma9tHeaX4xOsPgm4x6ZR+edT0b1HkNoyPtXweeOF0ro57dl4Gnhu+X1MtH+G8f5vUNYGlGdd/N6E/q/2H0SuSWrdQM/Aajg07LwPvmYA5/PtT4OKNfvMtW3f/DwxyeBG6a9XMN+FlGf9o/Djw2fL19kfbDBnNYpP3wU8A/DrUeA/5gGL+GUVAvA38BXDiMv2K4vjzcfs3Z5jbNL98ZK0nNLXLrRpI0BoNekpoz6CWpOYNekpoz6CWpOYNekpoz6CWpOYNekpr7P4q8h8AGnD67AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa2567ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# we can convert (small) Spark data frames to `pandas`\n",
    "wordCountPDF = wordCountDF.toPandas()\n",
    "\n",
    "# and then use pyplot (plt) to display the results\n",
    "# Please note that we call `plt.close()` first - this is needed for Databricks \n",
    "# to start a new plot.\n",
    "\n",
    "plt.close()\n",
    "plt.hist(wordCountPDF['count'], bins = 20, log = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now play around modifyging some pieces of the code.\n",
    "\n",
    "When you are done and you are running off the local machine remeber **to close the notebook with `File/Close and Halt`**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
